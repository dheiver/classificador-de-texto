{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Claro! Aqui está um exemplo de artigo em markdown para o Medium sobre o classificador de texto:\n # Construindo um Classificador de Texto Avançado usando Python\n Neste artigo, vamos explorar como construir um classificador de texto avançado usando Python. O classificador utiliza técnicas de processamento de texto e aprendizado de máquina para realizar a classificação de frases em diferentes categorias. Vamos dar uma olhada no código e entender como ele funciona passo a passo.\n ## Pré-processamento de Texto\n O primeiro passo é pré-processar o texto para prepará-lo para a classificação. O código utiliza as bibliotecas  `re` ,  `demoji`  e  `nltk`  para remover emojis, caracteres especiais e números, além de converter o texto para minúsculas. Também são removidas as stopwords e aplicada a técnica de stemming para reduzir as palavras à sua forma básica.\n ## Carregando e Preparando os Dados\n Os dados de treinamento são carregados em um DataFrame do pandas. O código divide os dados em conjuntos de treinamento e teste. Em seguida, aplica a técnica de oversampling para lidar com o desbalanceamento das classes no conjunto de treinamento.\n ## Construindo o Modelo\n O modelo é construído utilizando uma combinação de diferentes classificadores, como regressão logística, floresta aleatória, SVM, boosting e XGBoost. Esses classificadores são combinados em um modelo de votação para melhorar a precisão da classificação. O código utiliza a biblioteca  `sklearn`  para implementar os classificadores e o modelo de votação.\n ## Avaliando o Modelo\n Após treinar o modelo, é feita a avaliação utilizando os dados de teste. O código calcula a acurácia, a matriz de confusão e o relatório de classificação do modelo. Essas métricas ajudam a entender o desempenho do classificador e a identificar possíveis melhorias.\n ## Conclusão\n Neste artigo, exploramos como construir um classificador de texto avançado usando Python. O código utiliza técnicas de pré-processamento de texto e aprendizado de máquina para realizar a classificação de frases. O modelo é construído com uma combinação de classificadores e é avaliado utilizando métricas de desempenho. Essa abordagem pode ser aplicada em uma variedade de problemas de classificação de texto, como análise de sentimentos, categorização de documentos e muito mais.\n Espero que este artigo tenha sido útil para entender como construir um classificador de texto avançado. Sinta-se à vontade para explorar o código e adaptá-lo para suas necessidades específicas. O código completo pode ser encontrado no [repositório GitHub](https://github.com/seu-usuario/nome-do-repositorio).\n Obrigado por ler e boa sorte em seus projetos de classificação de texto!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport demoji\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nnltk.download('stopwords')\n\n# TextClassifier Class\nclass TextClassifier:\n    def __init__(self):\n        self.vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n        self.classifiers = {\n            'Logistic Regression': LogisticRegression(),\n            'Random Forest': RandomForestClassifier(),\n            'Random Forest with Balanced Classes': RandomForestClassifier(class_weight='balanced'),\n            'SVM': SVC(),\n            'Gradient Boosting': GradientBoostingClassifier(),\n            'XGBoost': XGBClassifier()\n        }\n        self.ensemble_model = VotingClassifier(estimators=list(self.classifiers.items()), voting='hard')\n        \n    def preprocess_text(self, text):\n        # Remove emojis\n        text = demoji.replace(text, '')\n        # Remove special characters and numbers\n        text = re.sub(r'[^\\w\\s]', '', text)\n        # Convert to lowercase\n        text = text.lower()\n        # Remove stopwords and apply stemming\n        stop_words = set(stopwords.words('english'))\n        ps = PorterStemmer()\n        words = text.split()\n        words = [ps.stem(w) for w in words if w not in stop_words]\n        text = ' '.join(words)\n        return text\n    \n    def preprocess_and_train(self, df_train):\n        X_train = df_train['Frases'].apply(self.preprocess_text)\n        y_train = df_train['Classes']\n        \n        # Apply RandomOverSampler to handle class imbalance\n        ros = RandomOverSampler(random_state=42)\n        X_train_resampled, y_train_resampled = ros.fit_resample(X_train.to_frame(), y_train)\n        pipeline = Pipeline([\n            ('vectorizer', self.vectorizer),\n            ('classifier', self.ensemble_model)\n        ])\n        params = {\n            'classifier__Logistic Regression__C': [0.1, 1, 10],\n            'classifier__Random Forest__n_estimators': [50, 100, 200],\n            'classifier__Random Forest__max_depth': [None, 5, 10],\n            'classifier__Random Forest with Balanced Classes__n_estimators': [50, 100, 200],\n            'classifier__Random Forest with Balanced Classes__max_depth': [None, 5, 10],\n            'classifier__SVM__C': [0.1, 1, 10],\n            'classifier__SVM__kernel': ['linear', 'rbf', 'sigmoid'],\n            'classifier__Gradient Boosting__n_estimators': [50, 100, 200],\n            'classifier__Gradient Boosting__learning_rate': [0.01, 0.1, 0.2],\n            'classifier__XGBoost__n_estimators': [50, 100, 200],\n            'classifier__XGBoost__learning_rate': [0.01, 0.1, 0.2]\n        }\n            \n         # Check the number of unique classes in the resampled target variable\n        num_classes = len(set(y_train_resampled))\n        \n         # Choose the minimum between the number of classes and 5 (desired n_splits)\n        n_splits = min(num_classes, 5)\n        \n         # Use StratifiedKFold with the selected n_splits\n        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n        gs_model = GridSearchCV(pipeline, params, cv=cv)\n        gs_model.fit(X_train_resampled.squeeze(), y_train_resampled)\n        self.ensemble_model = gs_model.best_estimator_\n        \n    def evaluate(self, X_test, y_test):\n        X_test_preprocessed = X_test.apply(self.preprocess_text)\n        y_pred_ensemble = self.ensemble_model.predict(X_test_preprocessed)\n        print(\"Ensemble Model Metrics:\")\n        print(\"Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred_ensemble, zero_division=1))\n        print(\"Confusion Matrix:\")\n        print(confusion_matrix(y_test, y_pred_ensemble))\n        print(\"=\"*50)\n        return y_pred_ensemble\n    \n# Example usage\n# Load your training data into a pandas DataFrame 'df_train'\n# Split the data into 'X_train', 'y_train', 'X_test', 'y_test'\n# text_classifier = TextClassifier()\n# text_classifier.preprocess_and_train(df_train)\n# text_classifier.evaluate(X_test, y_test)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-03T12:25:47.452519Z","iopub.execute_input":"2023-08-03T12:25:47.452973Z","iopub.status.idle":"2023-08-03T12:25:49.307180Z","shell.execute_reply.started":"2023-08-03T12:25:47.452930Z","shell.execute_reply":"2023-08-03T12:25:49.306012Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install demoji","metadata":{"execution":{"iopub.status.busy":"2023-08-03T12:25:09.419313Z","iopub.execute_input":"2023-08-03T12:25:09.420087Z","iopub.status.idle":"2023-08-03T12:25:21.612126Z","shell.execute_reply.started":"2023-08-03T12:25:09.420049Z","shell.execute_reply":"2023-08-03T12:25:21.610788Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]}]}